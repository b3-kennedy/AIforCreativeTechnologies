{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AITransferLearning",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/b3-kennedy/AIforCreativeTechnologies/blob/main/Transfer%20Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JHiLXu3KUV0",
        "outputId": "e89965ab-58f1-44ce-d151-c92aa54e9de5"
      },
      "source": [
        "# import libraries\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "  print('CUDA is not available. Training on CPU.')\n",
        "else:\n",
        "  print('CUDA is available. Training on GPU.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. Training on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCtcVnmidRDH"
      },
      "source": [
        "# imshow function for displaying images\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqFOentoZYBq",
        "outputId": "d0ebbad3-6950-4862-f292-75a682c80f57"
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9-JJlGKcD4a"
      },
      "source": [
        "# dataset directory\n",
        "data_dir = '/content/gdrive/MyDrive/finaldataset'\n",
        "\n",
        "# define batch size\n",
        "batch_size = 128\n",
        "\n",
        "# define transforms\n",
        "# training (with random flips and rotation)\n",
        "train_transform = transforms.Compose([transforms.Resize(236), # resize to 236x?\n",
        "                                transforms.RandomRotation(5), # random rotation\n",
        "                                transforms.CenterCrop(224), # take a square (224x224) crop from the centre\n",
        "                                transforms.RandomHorizontalFlip(), # randomly flip on horizontal axis\n",
        "                                transforms.ToTensor(), # convert data to torch.FloatTensor\n",
        "                                transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                     [0.229, 0.224, 0.225])]) # normalise for each colour channel\n",
        "\n",
        "# validation and testing\n",
        "transform = transforms.Compose([transforms.Resize(224), # resize to 224x?\n",
        "                                transforms.CenterCrop(224), # take a square (224x224) crop from the centre\n",
        "                                transforms.ToTensor(), # convert data to torch.FloatTensor\n",
        "                                transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                     [0.229, 0.224, 0.225])]) # normalise for each colour channel\n",
        "\n",
        "# choose the training, validation and test datasets\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transform)\n",
        "val_data = datasets.ImageFolder(data_dir + '/val', transform=transform)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=transform)\n",
        "\n",
        "# prepare the data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfTR9KI1cEWK"
      },
      "source": [
        "# obtain one batch of training images\n",
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "# plot the first 4 images in the batch, along with the corresponding labels\n",
        "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
        "for ii in range(4):\n",
        "    ax = axes[ii]\n",
        "    imshow(images[ii], ax=ax, normalize=True)\n",
        "    ax.set_title(str(labels[ii].item())) \n",
        "# 0 is Lion's mane Jellyfish, 1 is Moon Jellyfish, 2 is Pacific Sea Nettle, 3 is White spotted Jellyfish"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVkYwkQn5s0J"
      },
      "source": [
        "#########################################################################\n",
        "# use a ResNet18 network\n",
        "# #########################################################################\n",
        "# NB This network requires an image input size of 3x224x224 and normalised using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# load a pre-trained ResNet network with 18 layers\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# # if we use the following code the pre-trained weights are frozen and we only update the final layer\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# get the number of inputs for the final layer (fc) of the network\n",
        "num_ftrs = model.fc.in_features\n",
        "# replace the final layer so that the output is number of classes\n",
        "model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if train_on_gpu:\n",
        "    model.cuda()\n",
        "\n",
        "print(model)\n",
        "\n",
        "# #########################################################################\n",
        "# #########################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPRSMyWuu6w4"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# specify loss function (cross entropy loss)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# specify optimiser (Adam optimiser) and learning rate = 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5Ki4vXMgEul"
      },
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 30\n",
        "\n",
        "# initialise tracker for minimum validation loss\n",
        "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
        "\n",
        "# create empty lists to store the training and validation losses\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # monitor training loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train() # prep model for training\n",
        "    for data, target in train_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update running training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval() # prep model for evaluation\n",
        "    for data, target in val_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update running validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(val_loader.sampler)\n",
        "\n",
        "    # store the training and validation losses for later visualisation\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(valid_loss)\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), '/content/gdrive/MyDrive/frozen weights model.pt') # save in colab # save in google drive\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1q2XDo3BC6K"
      },
      "source": [
        "# visualise the training and validation losses over time\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PWSJstNgN7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8a7d7dd-82dd-4e58-f913-12c39072f7e3"
      },
      "source": [
        "# Load the Model with the Lowest Validation Loss\n",
        "model.load_state_dict(torch.load('//content/gdrive/MyDrive/resnet18_unfrozen.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTGAtEm27USp"
      },
      "source": [
        "# Test the Trained Network\n",
        "\n",
        "# initialize lists to monitor test loss and accuracy\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval() # prep model for evaluation\n",
        "\n",
        "for data, target in test_loader:\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if train_on_gpu:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # compare predictions to true label\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(len(target)):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "# change value here to number of classes\n",
        "for i in range(5):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpInUKFI7eym"
      },
      "source": [
        "# Visualize Sample Test Results\n",
        "\n",
        "# obtain one batch of test images\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "images.numpy()\n",
        "\n",
        "# move model inputs to cuda, if GPU available\n",
        "if train_on_gpu:\n",
        "    images = images.cuda()\n",
        "\n",
        "# get sample outputs\n",
        "output = model(images)\n",
        "# convert output probabilities to predicted class\n",
        "_, preds_tensor = torch.max(output, 1)\n",
        "preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
        "\n",
        "# plot the first 4 images in the batch, along with the corresponding labels\n",
        "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
        "for ii in range(4):\n",
        "    ax = axes[ii]\n",
        "    imshow(images.cpu()[ii], ax=ax, normalize=True)\n",
        "    ax.set_title(\"{} ({})\".format(str(preds[ii].item()), str(labels[ii].item())),\n",
        "                 color=(\"green\" if preds[ii]==labels[ii] else \"red\")) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}